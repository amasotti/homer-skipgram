{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation and Visualization (Skipgram Negative)\n",
    "\n",
    "Once the model has been trained, we can visualize the vector space and query for specific features/classes/word.\n",
    "\n",
    "Explorations:\n",
    "\n",
    "* Get vector for a given word\n",
    "* Predict context for the given word\n",
    "* Draw the vector space for n random words in the vocabulary\n",
    "* Build a dataframe, classify words (here I experimented with the greek diathesis) and draw the distribution plot\n",
    "\n",
    "For the visualizations I used the wonderful Bokeh library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "import os\n",
    "import re\n",
    "import pandas as pd \n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load saved files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(embeddings_path = 'data/models/embeddings.npy',\n",
    "                vocab='data/vocabs/Homer_word_frequencies_accented.json',\n",
    "                word2index=\"data/vocabs/Homer_word2index_accented.json\",\n",
    "                embeddings = 250,\n",
    "                device = 'cuda'\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabs and Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import vocab and lookup dictioanries\n",
    "with open(args.vocab, \"r\", encoding=\"utf-8\") as fp:\n",
    "    vocab = json.load(fp)\n",
    "    \n",
    "with open(args.word2index, \"r\", encoding=\"utf-8\") as fp:\n",
    "    word2index = json.load(fp)\n",
    "\n",
    "# Create a reverse lookup table\n",
    "index2word = {i: w for w, i in word2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.load(args.embeddings_path, allow_pickle=True)\n",
    "embeddings = torch.tensor(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding tensor([[ 0.6250,  0.2046, -0.0251,  ..., -0.3560, -0.0485, -0.1652],\n",
      "        [-0.0164, -0.3063,  0.3312,  ..., -0.0466,  0.1590,  0.0767],\n",
      "        [ 0.5669, -0.1569, -0.2868,  ..., -0.5518, -0.0069,  0.1337],\n",
      "        ...,\n",
      "        [ 0.0403,  0.2383,  0.3196,  ..., -0.0159,  0.3583,  0.1623],\n",
      "        [ 0.3061, -0.0333,  0.1572,  ..., -0.1225, -0.1025,  0.1806],\n",
      "        [ 0.1168,  0.1387, -0.1751,  ..., -0.0056,  0.0176,  0.0378]])\n"
     ]
    }
   ],
   "source": [
    "#embds = model.emb_context.weight.data.cpu()\n",
    "\n",
    "print('Embedding', embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  torch.Size([30657, 250])\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape: \", embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(token):\n",
    "    return embeddings[word2index[token], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0160, 0.1896, 0.1096, 0.0254])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "get_vector('θεά')[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(word2index.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import nearest_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(word, embeddings=embeddings, n=7):\n",
    "    target_vector = get_vector(word)\n",
    "    idx = nearest_word(target=target_vector, embeddings=embeddings,n=n, metrics=\"cosine\")\n",
    "    for i, index in enumerate(idx):\n",
    "        if index != word2index[word]:\n",
    "            print(f\"{i}) {index2word[index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) γλυκὺς\n",
      "2) νήδυμος\n",
      "3) λύων\n",
      "4) τεχνηέντως\n",
      "5) κεκμηῶτα\n",
      "6) λυσιμελὴς\n"
     ]
    }
   ],
   "source": [
    "most_similar('ὕπνος')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) ὠκὺς\n",
      "2) ποδάρκης\n",
      "3) ἀπέκτανε\n",
      "4) πέρσεν\n",
      "5) τάπησί\n",
      "6) δῖος\n"
     ]
    }
   ],
   "source": [
    "most_similar('Ἀχιλλεύς')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar('Ἀχιλλεύς')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analogy finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy(x1, x2, y, n=20):\n",
    "    '''\n",
    "    Analogy formula :\n",
    "            x1 : x2 = y : ?\n",
    "    \n",
    "    n (default 5) how many possible answers do you want?\n",
    "    '''\n",
    "    vec_x1 = get_vector(x1)\n",
    "    vec_x2 = get_vector(x2)\n",
    "    vec_y = get_vector(y)\n",
    "    vec_unknown = (vec_x1 - vec_x2) + vec_y\n",
    "    \n",
    "    idx_next_words = nearest_word(vec_unknown, embeddings, n=n)\n",
    "    \n",
    "    for i, idx in enumerate(idx_next_words):\n",
    "        print(f\"{i}) {index2word[idx]})\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0) θεά)\n",
      "1) πότνα)\n",
      "2) θεός)\n",
      "3) παρθενικῇ)\n",
      "4) ἐπαρήγοις)\n",
      "5) νεήνιδι)\n",
      "6) ἁμόθεν)\n",
      "7) Ἄρτεμι)\n",
      "8) ἐχούσῃ)\n",
      "9) ἐπίρροθος)\n",
      "10) κάλπιν)\n",
      "11) μήδεαι)\n",
      "12) πρόφρασσʼ)\n",
      "13) χώεο)\n",
      "14) ἀγαθή)\n",
      "15) φήνῃ)\n",
      "16) ἱρῶν)\n",
      "17) ἐπεμάσσατʼ)\n",
      "18) ἐᾷ)\n",
      "19) ὀμόσσαι)\n"
     ]
    }
   ],
   "source": [
    "analogy('θεός', \"ἀνήρ\", \"θεά\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scaler and dimensionality reducer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 61 nearest neighbors...\n",
      "[t-SNE] Indexed 30657 samples in 2.167s...\n"
     ]
    }
   ],
   "source": [
    "vectors_tsne = TSNE(n_components=2,\n",
    "                    perplexity = 20,\n",
    "                    metric='euclidean',\n",
    "                    n_iter=700,\n",
    "                    verbose=3,\n",
    "                    n_jobs=6).fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_tsne = scaler.fit_transform(vectors_tsne)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build datframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def generate_random_idx(n=250):\n",
    "    rand_numbers = []\n",
    "    for _ in range(n):\n",
    "        rand_numbers.append(random.randint(0, len(words)-1))\n",
    "    return rand_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_words = [\"εθηκε\", 'επος', 'εφατʼ', 'ελαφρον', 'Αθηνη']\n",
    "\n",
    "# extract n random words from the vocabulary\n",
    "test_idx = generate_random_idx(n=50)\n",
    "test_words = [index2word[i] for i in test_idx]\n",
    "\n",
    "# extract the vector coordinates\n",
    "x= []\n",
    "y = []\n",
    "for word in test_words:\n",
    "    x.append(vectors_tsne[word2index[word],0])\n",
    "    y.append(vectors_tsne[word2index[word], 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame({'word' : test_words, 'x' : x, 'y' : y})\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh.models as bm, bokeh.plotting as pl\n",
    "from bokeh.io import output_notebook, export_png\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.transform import factor_cmap, factor_mark, linear_cmap\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.palettes import Category20_9\n",
    "def draw_test_words(data, alpha=0.69,width=600, height=400, show=True):\n",
    "    \"\"\" draws an interactive plot for data points with auxilirary info on hover \"\"\"\n",
    "    \n",
    "    src = bm.ColumnDataSource(data)\n",
    "    \n",
    "    mapper = linear_cmap(field_name='y', palette=Category20_9 ,low=min(y) ,high=max(y))\n",
    "    fig = pl.figure(active_scroll='wheel_zoom', width=width, height=height, title=\"Visualize chosen vectors\")\n",
    "    \n",
    "    fig.scatter('x','y',\n",
    "                size=10,\n",
    "                line_color=mapper,\n",
    "                color=mapper,\n",
    "                fill_alpha=alpha,\n",
    "                source=src)\n",
    "\n",
    "    \n",
    "    fig.add_tools(bm.HoverTool(tooltips=[(\"token\", \"@word\")]))\n",
    "    if show: pl.show(fig)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_test_words(data=test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset media vs. active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=vectors_tsne, columns=[\"x\", \"y\"])\n",
    "df['token'] = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find and insert labels for diathesis\n",
    "classe = []\n",
    "faslse_positives = [\"που\", \"αυτου\",\"και\",\"ειναι\",\"κατʼ\"]\n",
    "for tok in df['token']:\n",
    "    if tok in faslse_positives:\n",
    "        classe.append('non_verb')\n",
    "        continue\n",
    "        # just a selection of middle endings\n",
    "    regex = r\"\\w+(μαι|σαι|σο|ται|το|μεθα|μεθʼ|σθε|σθʼ|σθ|νται|ντʼ|ντο|σθαι|μην|ου|ιο|μην|σθω|σθων|μεν\\w{1,3})\\b\"\n",
    "    match = re.match(regex, tok)\n",
    "    if match:\n",
    "        classe.append('medium')\n",
    "    else:\n",
    "        # just a selection of active endings\n",
    "        regex = r\"\\w+(μι|σι|τι|μεν|τε|ντι|ω|εις|ει|μεν|τε|ουσι|ον|οιμι)\\b\"\n",
    "        match = re.match(regex, tok)\n",
    "        if match:\n",
    "            classe.append('active')\n",
    "        else:\n",
    "            classe.append('non_verb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add labels\n",
    "df['label'] = classe\n",
    "#sdf.to_csv(\"data/assets/tsne_df_pyTorch.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"label\"] != \"non_verb\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_groups(data, radius=10, alpha=0.25,width=600, height=400, show=True, markers=['triangle', \"diamond\"],\n",
    "                colorstyle=[\"#fca486\", \"#91bfdb\"], labels=['medium', 'active'], name=\"plot.png\"):\n",
    "    \"\"\" draws an interactive plot for data points with auxilirary info on hover \"\"\"\n",
    "    \n",
    "    MARKERS = markers\n",
    "    LABEL = labels\n",
    "    \n",
    "    src = bm.ColumnDataSource(data)\n",
    "    \n",
    "    fig = pl.figure(active_scroll='wheel_zoom', width=width, height=height, title=\"Skip Gram\")\n",
    "    \n",
    "    fig.scatter('x','y',\n",
    "                size=10,\n",
    "                legend_field=\"label\",\n",
    "                marker=factor_mark('label', MARKERS, LABEL),\n",
    "                color=factor_cmap('label', colorstyle, LABEL),\n",
    "                source=src)\n",
    "\n",
    "    \n",
    "    fig.add_tools(bm.HoverTool(tooltips=[(\"token\", \"@token\")]))\n",
    "    export_png(fig, filename=\"data/assets/\"+name)\n",
    "    if show: pl.show(fig)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_groups(data=df,name=\"torch_skip_0502_euclidean_tsne_perpl20.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
